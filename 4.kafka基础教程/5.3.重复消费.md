# 重复消费（Duplicate Consumption）

---

## Q1: 什么是重复消费？

**重复消费（Duplicate Consumption）** 是指同一条 Kafka 消息被 Consumer 处理了**多次**的现象。

### 核心概念

- **定义**：Consumer 对同一条消息（相同的 Topic、Partition、Offset）进行了多次处理
- **原因**：Kafka 的 **At-least-once** 语义保证消息至少被消费一次，但不保证只消费一次
- **影响**：可能导致业务逻辑重复执行，产生数据重复、状态不一致等问题

### 重复消费示例

```
场景：Consumer 处理消息后崩溃

时间线：
1. Consumer 拉取消息（Offset: 100）
2. 处理消息（更新数据库）
3. Consumer 崩溃（未提交 Offset）
4. Consumer 重启
5. 从 Offset 100 重新消费（重复处理）
```

### Kafka 的消费语义

Kafka 支持三种消费语义：

| 语义 | 说明 | 是否可能重复消费 | 是否可能丢失消息 |
|------|------|----------------|----------------|
| **At-least-once** | 至少消费一次 | ✅ 是 | ❌ 否 |
| **At-most-once** | 最多消费一次 | ❌ 否 | ✅ 是 |
| **Exactly-once** | 精确一次 | ❌ 否 | ❌ 否 |

**项目默认使用 At-least-once 语义**，因此可能出现重复消费。

---

## Q2: 什么情况下会发生重复消费？

### 1. Consumer 崩溃或重启

**场景**：Consumer 处理消息后、提交 Offset 前崩溃。

```
1. Consumer 拉取消息（Offset: 100）
   ↓
2. 处理消息（调用 Consume 方法）
   ↓
3. Consumer 崩溃（未提交 Offset）
   ↓
4. Consumer 重启
   ↓
5. 从 Offset 100 重新消费（重复处理）
```

**原因**：
- Offset 未提交，Kafka 认为消息未被消费
- Consumer 重启后从上次 Offset 继续消费

### 2. Rebalance（重平衡）

**场景**：Consumer Group 发生 Rebalance，Partition 重新分配。

```
初始状态：
- Consumer 1 → Partition 0 (Offset: 100)
- Consumer 2 → Partition 1

Rebalance 触发（Consumer 2 崩溃）：
- Consumer 1 → Partition 0 (Offset: 100), Partition 1

问题：
- Partition 0 的 Offset 100 可能被重复消费
```

**原因**：
- Rebalance 期间，Consumer 可能已经处理了消息但未提交 Offset
- Rebalance 完成后，新的 Consumer 从上次提交的 Offset 继续消费

### 3. 自动提交 Offset 的时机问题

**场景**：自动提交 Offset 的间隔设置不当。

```
配置：
auto.commit.interval.ms=5000  # 5 秒自动提交一次

时间线：
1. T0: Consumer 拉取消息（Offset: 100-199）
2. T1: 处理消息（Offset: 100-150）
3. T2: 自动提交 Offset（提交到 200）← 提交了未处理的消息
4. T3: Consumer 崩溃

结果：
- Offset 151-199 的消息被跳过（丢失）
- 如果 Consumer 重启后重新拉取，Offset 100-150 可能被重复消费
```

**原因**：
- 自动提交是基于时间间隔，不是基于消息处理完成
- 可能提交了未处理的消息，也可能未提交已处理的消息

### 4. 手动提交 Offset 失败

**场景**：手动提交 Offset 时网络错误或超时。

```
1. Consumer 处理消息（Offset: 100）
   ↓
2. 手动提交 Offset（网络错误）
   ↓
3. Consumer 重试提交（仍然失败）
   ↓
4. Consumer 继续处理下一条消息（Offset: 101）
   ↓
5. Offset 100 未提交，可能被重复消费
```

**原因**：
- 网络问题导致 Offset 提交失败
- Consumer 继续处理后续消息，但之前的 Offset 未提交

### 5. 消息处理失败后的重试

**场景**：消息处理失败，Consumer 返回错误，消息被重试。

```
1. Consumer 拉取消息（Offset: 100）
   ↓
2. 处理消息（返回错误）
   ↓
3. Offset 未提交
   ↓
4. Kafka 重试消息（再次消费 Offset: 100）
   ↓
5. 如果处理成功，Offset 被提交
   ↓
6. 但如果处理逻辑不是幂等的，可能产生副作用
```

**原因**：
- Kafka 的重试机制会重新消费失败的消息
- 如果处理逻辑不是幂等的，会产生重复操作

---

## Q3: 重复消费会发生什么问题？

### 1. 数据重复

**场景**：重复插入数据库记录。

```
第一次消费：
- 插入交易记录（TxHash: 0x123...）

重复消费：
- 再次插入交易记录（TxHash: 0x123...）← 重复数据
```

**影响**：
- 数据库中存在重复记录
- 统计数据不准确
- 查询结果包含重复数据

### 2. 状态不一致

**场景**：重复更新状态。

```
第一次消费：
- 更新订单状态：待支付 → 已支付

重复消费：
- 再次更新订单状态：已支付 → 已支付（可能触发其他逻辑）
```

**影响**：
- 业务状态可能被错误更新
- 可能触发不应该触发的业务逻辑
- 导致数据不一致

### 3. 重复计算

**场景**：重复计算统计数据。

```
第一次消费：
- 计算 K 线数据：Volume += 1000

重复消费：
- 再次计算 K 线数据：Volume += 1000 ← 重复计算
```

**影响**：
- 统计数据不准确（Volume 被重复累加）
- K 线数据错误
- 影响价格和交易量分析

### 4. 重复发送通知

**场景**：重复发送消息通知。

```
第一次消费：
- 发送邮件通知用户

重复消费：
- 再次发送邮件通知用户 ← 用户收到重复通知
```

**影响**：
- 用户体验差（收到重复通知）
- 可能触发限流或封禁
- 增加系统负载

### 5. 重复扣款或转账

**场景**：重复执行金融操作（最严重）。

```
第一次消费：
- 执行转账操作：账户 A → 账户 B（100 USDT）

重复消费：
- 再次执行转账操作：账户 A → 账户 B（100 USDT）← 重复扣款
```

**影响**：
- **资金损失**（最严重的问题）
- 账户余额错误
- 需要人工介入修复

---

## Q4: 如何避免重复消费？

### 1. 实现幂等性（Idempotency）

**定义**：幂等性是指多次执行同一个操作，结果与执行一次相同。

#### 方法 1：使用唯一标识符

**原理**：为每条消息生成唯一标识符，处理前检查是否已处理。

```go
func (t *TradeConsumer) Consume(ctx context.Context, key kafka.Message) error {
    var tradeMsg []*model.TradeWithPair
    json.Unmarshal(key.Value, &tradeMsg)
    
    for _, trade := range tradeMsg {
        // 1. 检查是否已处理（使用 TxHash 作为唯一标识）
        exists, err := t.checkTradeExists(ctx, trade.TxHash)
        if err != nil {
            return err
        }
        if exists {
            logx.Infof("Trade already processed: %s", trade.TxHash)
            continue  // 跳过已处理的消息
        }
        
        // 2. 处理消息
        if err := t.processTrade(ctx, trade); err != nil {
            return err
        }
        
        // 3. 标记为已处理
        t.markTradeAsProcessed(ctx, trade.TxHash)
    }
    
    return nil
}
```

#### 方法 2：使用数据库唯一约束

**原理**：利用数据库的唯一约束防止重复插入。

**项目中的实现**（`apps/dataflow/internal/data/kline_mysql.go`）：

```go
func (repo *KlineMysqlRepo) SaveKline(ctx context.Context, interval constants.KlineInterval, candleTime int64, klines []*Kline) error {
    // 使用 ON CONFLICT 处理重复插入
    err := repo.db.WithContext(ctx).
        Table(tableName).
        Clauses(clause.OnConflict{
            // 唯一约束：chain_id, pair_address, candle_time
            Columns: []clause.Column{
                {Name: "chain_id"}, 
                {Name: "pair_address"}, 
                {Name: "candle_time"},
            },
            // 冲突时更新现有记录
            DoUpdates: clause.AssignmentColumns([]string{
                "open_at", "close_at", "o", "c", "h", "l", 
                "v", "t", "a", "count", "buy_count", "sell_count", "updated_at",
            }),
        }).CreateInBatches(klines, len(batch)).Error
    
    return err
}
```

**数据库表结构**（`model/sql/kline.sql`）：

```sql
CREATE TABLE `trade_kline_1m` (
    `id`           bigint          NOT NULL AUTO_INCREMENT,
    `chain_id`     int             NOT NULL,
    `pair_address` varchar(64)     NOT NULL,
    `candle_time`  bigint          NOT NULL,
    -- ... 其他字段
    PRIMARY KEY (`id`),
    -- 唯一约束：防止重复插入
    UNIQUE KEY `chain_id_address_index` (`chain_id`,`pair_address`,`candle_time`)
) ENGINE=InnoDB;
```

**优点**：
- **数据库层面保证**：即使重复消费，数据库也会拒绝重复插入
- **自动处理**：使用 `ON CONFLICT` 可以更新现有记录，而不是报错
- **可靠性高**：不依赖应用层逻辑

### 2. 使用分布式锁

**原理**：在处理消息前获取分布式锁，确保同一消息只被处理一次。

```go
func (t *TradeConsumer) Consume(ctx context.Context, key kafka.Message) error {
    var tradeMsg []*model.TradeWithPair
    json.Unmarshal(key.Value, &tradeMsg)
    
    for _, trade := range tradeMsg {
        // 1. 获取分布式锁（使用 TxHash 作为锁的 key）
        lockKey := fmt.Sprintf("trade_lock:%s", trade.TxHash)
        lock, err := t.redisClient.SetNX(ctx, lockKey, "1", 10*time.Minute).Result()
        if err != nil || !lock {
            logx.Infof("Trade is being processed by another consumer: %s", trade.TxHash)
            continue  // 跳过，其他 Consumer 正在处理
        }
        defer t.redisClient.Del(ctx, lockKey)  // 处理完成后释放锁
        
        // 2. 处理消息
        if err := t.processTrade(ctx, trade); err != nil {
            return err
        }
    }
    
    return nil
}
```

**优点**：
- 防止多个 Consumer 同时处理同一条消息
- 适用于分布式环境

**缺点**：
- 需要额外的 Redis 等存储系统
- 锁超时时间需要合理设置

### 3. 使用消息去重表

**原理**：维护一个消息处理记录表，记录已处理的消息。

```go
// 消息去重表
type MessageDedup struct {
    MessageID string    `gorm:"primary_key"`  // Topic-Partition-Offset
    ProcessedAt time.Time
}

func (t *TradeConsumer) Consume(ctx context.Context, key kafka.Message) error {
    // 1. 生成消息唯一 ID
    messageID := fmt.Sprintf("%s-%d-%d", key.Topic, key.Partition, key.Offset)
    
    // 2. 检查是否已处理
    var dedup MessageDedup
    err := t.db.Where("message_id = ?", messageID).First(&dedup).Error
    if err == nil {
        logx.Infof("Message already processed: %s", messageID)
        return nil  // 已处理，跳过
    }
    
    // 3. 处理消息
    if err := t.processMessage(ctx, key); err != nil {
        return err
    }
    
    // 4. 记录已处理
    t.db.Create(&MessageDedup{
        MessageID: messageID,
        ProcessedAt: time.Now(),
    })
    
    return nil
}
```

**优点**：
- 可以精确追踪每条消息的处理状态
- 支持查询和审计

**缺点**：
- 需要额外的存储空间
- 需要定期清理旧记录

### 4. 使用 Kafka 事务（Exactly-once）

**原理**：使用 Kafka 的事务机制保证 Exactly-once 语义。

```go
// 配置 Producer 启用事务
config.Producer.Transaction.ID = "unique-transaction-id"
config.Producer.Idempotent = true  // 启用幂等性

producer, err := sarama.NewAsyncProducer(brokers, config)
producer.BeginTxn()

// 发送消息
producer.Input() <- &sarama.ProducerMessage{
    Topic: "output-topic",
    Value: sarama.StringEncoder("message"),
}

// 提交 Offset 和消息到事务
producer.AddOffsetsToTxn(offsets, "consumer-group")
producer.CommitTxn()
```

**优点**：
- **Kafka 原生支持**：保证 Exactly-once 语义
- **可靠性高**：不依赖应用层逻辑

**缺点**：
- **性能开销**：事务机制有性能开销
- **复杂度高**：需要正确配置和管理事务
- **项目未使用**：项目目前使用 At-least-once + 幂等性设计

---

## Q5: 项目中如何解决该问题的？

### 1. K 线数据的幂等性设计

**场景**：Dataflow 服务消费交易数据，生成 K 线数据。

#### 问题分析

- **重复消费风险**：如果交易消息被重复消费，K 线数据可能被重复计算
- **影响**：Volume、Count 等统计数据可能不准确

#### 解决方案

**方法 1：数据库唯一约束 + ON CONFLICT**

**实现位置**：`apps/dataflow/internal/data/kline_mysql.go`

```go
func (repo *KlineMysqlRepo) SaveKline(ctx context.Context, interval constants.KlineInterval, candleTime int64, klines []*Kline) error {
    err := repo.db.WithContext(ctx).
        Table(tableName).
        Clauses(clause.OnConflict{
            // 唯一约束：chain_id, pair_address, candle_time
            Columns: []clause.Column{
                {Name: "chain_id"}, 
                {Name: "pair_address"}, 
                {Name: "candle_time"},
            },
            // 冲突时更新现有记录（幂等性）
            DoUpdates: clause.AssignmentColumns([]string{
                "open_at", "close_at", "o", "c", "h", "l", 
                "v", "t", "a", "count", "buy_count", "sell_count", "updated_at",
            }),
        }).CreateInBatches(klines, len(batch)).Error
    
    return err
}
```

**工作原理**：
1. **唯一约束**：`(chain_id, pair_address, candle_time)` 确保同一时间段的 K 线数据唯一
2. **ON CONFLICT**：如果重复插入，更新现有记录而不是报错
3. **幂等性**：即使重复消费，K 线数据也会被正确更新

**数据库表结构**：

```sql
CREATE TABLE `trade_kline_1m` (
    `id`           bigint          NOT NULL AUTO_INCREMENT,
    `chain_id`     int             NOT NULL,
    `pair_address` varchar(64)     NOT NULL,
    `candle_time`  bigint          NOT NULL,
    -- ... 其他字段
    PRIMARY KEY (`id`),
    -- 唯一约束：防止重复插入
    UNIQUE KEY `chain_id_address_index` (`chain_id`,`pair_address`,`candle_time`)
) ENGINE=InnoDB;
```

**优点**：
- ✅ **数据库层面保证**：即使重复消费，数据库也会正确处理
- ✅ **自动更新**：使用 `ON CONFLICT` 更新现有记录，而不是报错
- ✅ **可靠性高**：不依赖应用层逻辑

#### 方法 2：K 线生成的幂等性

**实现位置**：`apps/dataflow/internal/logic/kline/kline.go`

```go
func GenerateKlinesWithTradesFromTrades(ctx context.Context, trades []*model.TradeWithPair) map[string]*KlineWithTrade {
    klineMap := make(map[string]*KlineWithTrade)
    
    for _, trade := range trades {
        // 生成 K 线 Key：chainId-pairAddress-interval-candleTime
        key := fmt.Sprintf("%d-%s-%s-%d", 
            trade.ChainId, 
            trade.PairAddr, 
            interval, 
            candleTime)
        
        // 如果已存在，合并数据（幂等性）
        if existing, ok := klineMap[key]; ok {
            // 合并交易数据
            existing.Trades = append(existing.Trades, trade)
            // 更新 K 线数据（取最大值、最小值等）
            updateKline(existing.Klines[0], trade)
        } else {
            // 创建新的 K 线数据
            klineMap[key] = &KlineWithTrade{
                Klines: []*datakline.Kline{newKline},
                Trades: []*model.TradeWithPair{trade},
            }
        }
    }
    
    return klineMap
}
```

**工作原理**：
- **Key 唯一性**：使用 `chainId-pairAddress-interval-candleTime` 作为 Key
- **合并数据**：如果同一时间段的 K 线已存在，合并交易数据
- **幂等性**：即使重复消费，K 线数据也会被正确合并

### 2. Consumer 服务的重复数据处理

**场景**：Consumer 服务从链上同步数据，可能遇到重复的交易或 Pair。

**实现位置**：`apps/consumer/internal/logic/sol/block/db.go`

```go
func (s *BlockService) InsertPair(ctx context.Context, pair *model.Pair) error {
    err := s.svcCtx.PairModel.Insert(ctx, pair)
    if err != nil {
        // 检查是否是重复插入错误
        if strings.Contains(err.Error(), "Duplicate entry") {
            logx.Infof("Pair already exists: %s", pair.Addr)
            return nil  // 幂等返回，不报错
        }
        return err
    }
    return nil
}
```

**工作原理**：
- **错误处理**：捕获 "Duplicate entry" 错误
- **幂等返回**：如果数据已存在，返回 `nil` 而不是报错
- **避免重复插入**：防止重复消费导致的数据重复

### 3. Rebate 服务的重复回调处理

**场景**：Rebate 服务处理提现回调，可能收到重复的回调请求。

**实现位置**：`apps/rebate/internal/task/rebate_withdraw_status.go`

```go
func (t *RebateWithdrawStatusTask) HandleCallback(in *rebate.RebateWithdrawCallbackRequest) error {
    // 检查是否已处理过该回调
    exists, err := t.checkCallbackExists(in.ChainId, in.TxHash)
    if err != nil {
        return err
    }
    if exists {
        logx.Error("duplicate callback, ", "chainId: ", in.ChainId, "txHash: ", in.TxHash)
        return fmt.Errorf("duplicate callback, chainId: %v, txHash: %v", in.ChainId, in.TxHash)
    }
    
    // 处理回调
    // ...
    
    return nil
}
```

**工作原理**：
- **唯一标识**：使用 `ChainId + TxHash` 作为唯一标识
- **重复检查**：处理前检查是否已处理过
- **拒绝重复**：如果已处理，返回错误而不是重复处理

### 4. 项目中的最佳实践总结

#### 实践 1：数据库唯一约束

**适用场景**：需要持久化存储的数据（K 线、交易记录等）

**实现方式**：
- 在数据库表上创建唯一约束
- 使用 `ON CONFLICT` 处理重复插入
- 更新现有记录而不是报错

**优点**：
- 数据库层面保证，可靠性高
- 不依赖应用层逻辑

#### 实践 2：业务逻辑幂等性

**适用场景**：K 线生成、数据聚合等

**实现方式**：
- 使用唯一 Key 合并数据
- 重复处理时更新而不是创建新记录

**优点**：
- 应用层控制，灵活性高
- 可以处理复杂的业务逻辑

#### 实践 3：错误处理中的幂等性

**适用场景**：数据插入、状态更新等

**实现方式**：
- 捕获 "Duplicate entry" 错误
- 幂等返回，不报错

**优点**：
- 简单易实现
- 适用于简单的插入操作

---

## 重复消费的最佳实践

### 1. **设计幂等性操作**

- **唯一标识**：为每条消息或操作生成唯一标识
- **幂等检查**：处理前检查是否已处理
- **幂等更新**：重复处理时更新而不是创建

### 2. **使用数据库约束**

- **唯一约束**：在数据库表上创建唯一约束
- **ON CONFLICT**：使用 `ON CONFLICT` 处理重复插入
- **更新策略**：冲突时更新现有记录

### 3. **合理设置 Offset 提交**

- **手动提交**：处理成功后手动提交 Offset
- **批量提交**：批量处理时批量提交 Offset
- **错误处理**：处理失败时不提交 Offset

### 4. **监控和告警**

- **监控 Lag**：监控 Consumer Group 的 Lag
- **告警机制**：Lag 过大时告警
- **日志记录**：记录重复消费的情况

### 5. **测试重复消费场景**

- **单元测试**：测试幂等性逻辑
- **集成测试**：测试重复消费场景
- **压力测试**：测试高并发下的幂等性

---

## 相关文档

- [Consumer 消费者](./5.Consumer消费者.md)
- [Consumer Group 消费者组](./5.1.消费者组.md)
- [Offset 管理](./5.2.offset管理.md)
- [Producer 生产者](./4.Producer生产者.md)
