# Offset 管理（偏移量管理）

---

## Q1: 什么是 Offset？

**Offset（偏移量）** 是 Kafka 中用于标识消息在 Partition 中位置的唯一标识符。

### 核心概念

- **定义**：Offset 是一个**递增的整数**，表示消息在 Partition 中的位置
- **作用**：
  - 标识消息在 Partition 中的位置
  - 记录 Consumer 的消费进度
  - 支持 Consumer 从指定位置恢复消费

### Offset 的特点

1. **Partition 级别**
   - 每个 Partition 都有自己独立的 Offset 序列
   - Offset 从 0 开始，每条消息的 Offset 递增 1

2. **持久化存储**
   - Offset 存储在 Kafka 的 `__consumer_offsets` Topic 中
   - 每个 Consumer Group 维护自己的 Offset

3. **不可变**
   - 消息的 Offset 一旦分配就不会改变
   - 即使消息被删除，Offset 也不会被重用

### Offset 示例

```
Partition 0:
┌─────────┬──────────────┬─────────┐
│ Offset  │    Message   │  Size   │
├─────────┼──────────────┼─────────┤
│    0    │  Message A   │  100B   │
│    1    │  Message B   │  200B   │
│    2    │  Message C   │  150B   │
│    3    │  Message D   │  300B   │
│    4    │  Message E   │  250B   │
└─────────┴──────────────┴─────────┘
         ↑
    Consumer 当前消费到 Offset 2
    （已消费 Message A, B, C）
```

### Offset 的作用

1. **消费进度追踪**
   - Consumer 记录已消费消息的 Offset
   - 重启后可以从上次 Offset 继续消费

2. **消息定位**
   - 通过 Offset 可以快速定位到指定消息
   - 支持按 Offset 范围查询消息

3. **重复消费控制**
   - 通过 Offset 可以避免重复消费
   - 确保消息只被处理一次

---

## Q2: 如何追踪消息的 Offset？

### 1. Consumer 自动追踪

**机制**：Consumer 会自动追踪每个 Partition 的消费进度。

#### 消费流程

```
1. Consumer 从 Broker 拉取消息
   ↓
2. 处理消息（调用 Consume 方法）
   ↓
3. 标记消息为已处理（MarkMessage）
   ↓
4. 提交 Offset（自动或手动）
```

#### 项目中的实现

**Dataflow/Market 服务**：
```go
func (t *TradeConsumer) Consume(ctx context.Context, key kafka.Message) error {
    // key.Offset 包含当前消息的 Offset
    logx.Infof("kafka key offset: %d, partition: %d", 
        key.Offset, key.Partition)
    
    // 处理消息
    // ...
    
    // 返回 nil 表示处理成功，Offset 会被自动提交
    return nil
}
```

**消息对象包含 Offset 信息**：
```go
type Message struct {
    Topic     string
    Partition int
    Offset    int64      // 消息的 Offset
    Key       []byte
    Value     []byte
    Headers   []Header
    Time      time.Time
}
```

### 2. 查看 Consumer Group 的 Offset

#### 使用 Kafka 命令行工具

```bash
# 查看 Consumer Group 的消费进度
kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group data-flow-default-group-1888 \
  --describe
```

**输出示例**：
```
GROUP                    TOPIC           PARTITION  CURRENT-OFFSET  LAG
data-flow-group         sol-trades      0          1000            0
data-flow-group         sol-trades      1          2000            0
data-flow-group         sol-trades      2          1500            0
```

**字段说明**：
- `CURRENT-OFFSET`：Consumer Group 当前已提交的 Offset
- `LAG`：Consumer Group 落后 Producer 的消息数量
  - `LAG = High Watermark - CURRENT-OFFSET`
  - `LAG = 0` 表示已消费所有消息

#### 查看特定 Partition 的 Offset

```bash
# 查看 Partition 的 High Watermark（最新消息的 Offset）
kafka-run-class.sh kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic sol-trades \
  --partitions 0
```

**输出示例**：
```
sol-trades:0:1000
```

**说明**：
- `sol-trades:0:1000` 表示 Topic `sol-trades` 的 Partition 0 的最新 Offset 是 1000
- 这意味着该 Partition 有 1000 条消息（Offset 0-999）

### 3. Offset 存储位置

#### Kafka 内部存储

- **Topic**：`__consumer_offsets`
- **格式**：Compacted Topic（只保留最新的 Offset）
- **Key**：`<GroupId, Topic, Partition>`
- **Value**：`<Offset, Metadata, Timestamp>`

#### 查看 Offset 存储

```bash
# 查看 __consumer_offsets Topic 的内容
kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic __consumer_offsets \
  --from-beginning \
  --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter"
```

---

## Q3: 如何提交 Offset？

### Offset 提交方式

Kafka 支持两种 Offset 提交方式：

1. **自动提交（Auto Commit）**
2. **手动提交（Manual Commit）**

### 1. 自动提交（Auto Commit）

**机制**：Consumer 定期自动提交 Offset，无需手动干预。

#### 配置

**项目配置**（`apps/dataflow/etc/dataflow.yaml`）：
```yaml
KqSol:
  Offset: last  # 初始 Offset 位置
  # 自动提交（go-queue/kq 库默认启用）
```

**Kafka 配置**（Java）：
```properties
# 启用自动提交
enable.auto.commit=true

# 自动提交间隔（毫秒）
auto.commit.interval.ms=5000
```

#### 工作原理

```
1. Consumer 拉取消息
   ↓
2. 处理消息
   ↓
3. 每隔 auto.commit.interval.ms 自动提交 Offset
   ↓
4. 提交到 __consumer_offsets Topic
```

#### 优点

- **简单**：无需手动管理 Offset
- **高效**：批量提交，减少网络开销

#### 缺点

- **可能丢失消息**：如果 Consumer 在处理消息后、提交 Offset 前崩溃，消息会被重复消费
- **可能重复消费**：如果 Consumer 在处理消息前、提交 Offset 后崩溃，消息会被跳过

**示例**：
```
时间线：
1. Consumer 拉取消息（Offset 0-99）
2. 处理消息（Offset 0-50）
3. 自动提交 Offset（提交到 100）← 提交了未处理的消息
4. Consumer 崩溃

结果：Offset 51-99 的消息被跳过，丢失了
```

### 2. 手动提交（Manual Commit）

**机制**：Consumer 在处理完消息后，手动调用提交 Offset 的方法。

#### 使用 Sarama 库（Go）

**示例代码**：
```go
func (h *ConsumerGroupHandler) ConsumeClaim(
    session sarama.ConsumerGroupSession,
    claim sarama.ConsumerGroupClaim,
) error {
    for {
        select {
        case message := <-claim.Messages():
            if message == nil {
                return nil
            }
            
            // 1. 处理消息
            if err := h.processMessage(message); err != nil {
                logx.Errorf("Failed to process: %v", err)
                continue  // 不提交 Offset，消息会被重试
            }
            
            // 2. 标记消息为已处理
            session.MarkMessage(message, "")
            
            // 3. 手动提交 Offset（同步）
            session.Commit()
            
        case <-session.Context().Done():
            return nil
        }
    }
}
```

#### 提交方式

**1. 同步提交（CommitSync）**
```go
// 同步提交，等待提交完成
session.Commit()
```

- **优点**：确保 Offset 已提交
- **缺点**：阻塞等待，影响性能

**2. 异步提交（CommitAsync）**
```go
// 异步提交，不等待结果
session.CommitAsync()
```

- **优点**：不阻塞，性能好
- **缺点**：不保证提交成功

#### 项目中的使用

**项目使用 go-queue/kq 库**：
- **自动提交**：`kq` 库默认使用自动提交
- **提交时机**：消息处理成功后（`Consume` 方法返回 `nil`）自动提交

**代码示例**：
```go
func (t *TradeConsumer) Consume(ctx context.Context, key kafka.Message) error {
    // 处理消息
    var tradeMsg []*model.TradeWithPair
    if err := json.Unmarshal(key.Value, &tradeMsg); err != nil {
        return err  // 返回错误，Offset 不会被提交，消息会被重试
    }
    
    // 处理业务逻辑
    // ...
    
    return nil  // 返回 nil，Offset 会被自动提交
}
```

### 3. Offset 提交策略

#### 策略 1：处理完立即提交

```go
func Consume(ctx context.Context, key kafka.Message) error {
    // 处理消息
    processMessage(key)
    
    // 立即提交
    return nil  // 自动提交
}
```

- **优点**：及时提交，减少重复消费
- **缺点**：如果后续处理失败，消息可能丢失

#### 策略 2：批量处理后再提交

```go
func Consume(ctx context.Context, key kafka.Message) error {
    // 添加到批量队列
    batch = append(batch, key)
    
    if len(batch) >= batchSize {
        // 批量处理
        processBatch(batch)
        
        // 批量提交
        return nil
    }
    
    return nil
}
```

- **优点**：提高吞吐量
- **缺点**：如果批量处理失败，可能重复消费多条消息

#### 策略 3：事务性提交

```go
// 使用 Kafka 事务 API
func Consume(ctx context.Context, key kafka.Message) error {
    // 1. 开始事务
    producer.BeginTransaction()
    
    // 2. 处理消息并发送下游
    processAndSend(key)
    
    // 3. 提交 Offset 和消息到事务
    producer.SendOffsetsToTransaction(offsets, consumerGroupMetadata)
    
    // 4. 提交事务
    producer.CommitTransaction()
    
    return nil
}
```

- **优点**：保证 Exactly-Once 语义
- **缺点**：性能开销较大

---

## Q4: Offset 在项目中的应用场景？

### 1. 初始 Offset 配置

**场景**：Consumer 首次启动时，从哪个 Offset 开始消费。

#### 项目配置

**配置文件**（`apps/dataflow/etc/dataflow.yaml`）：
```yaml
KqSol:
  Offset: last  # 从最新的消息开始消费
  Topic: sol-trades
  Group: data-flow-default-group-1888
```

**配置选项**：

| 选项 | 说明 | 使用场景 |
|------|------|---------|
| `last` | 从最新的消息开始消费 | 生产环境，只关心新消息 |
| `first` | 从最早的消息开始消费 | 需要处理历史数据 |
| `none` | 如果没有 Offset 则抛出异常 | 需要明确指定 Offset |

#### 不同服务的配置

**Dataflow 服务**：
```yaml
KqSol:
  Offset: last  # 只处理新消息，不处理历史数据
```

**原因**：
- Dataflow 服务负责实时生成 K 线数据
- 历史数据已经处理过，不需要重复处理
- 使用 `last` 可以快速启动，避免处理大量历史消息

**Consumer 服务（测试环境）**：
```yaml
KqSolTrades:
  Offset: last  # 测试环境，只处理新消息
```

### 2. Offset 追踪和监控

**场景**：监控 Consumer Group 的消费进度，及时发现消费延迟。

#### 项目中的实现

**Market 服务**（`apps/market/internal/mqs/consumers/trade_consumer.go`）：
```go
func (t *TradeConsumer) Consume(ctx context.Context, key kafka.Message) error {
    // 记录 Offset 信息用于监控
    logx.Infof("kafka key offset: %d, partition: %d, time: %v", 
        key.Offset, key.Partition, msg.CreateTime.Format(time.DateTime))
    
    // 处理消息
    // ...
    
    return nil
}
```

**用途**：
- **调试**：查看消息的 Offset 和 Partition，定位问题
- **监控**：记录消费进度，用于监控和告警
- **审计**：记录消息处理时间，用于性能分析

### 3. Offset 恢复和容错

**场景**：Consumer 崩溃后，从上次 Offset 恢复消费。

#### 容错流程

```
1. Consumer 正常消费（Offset: 100）
   ↓
2. Consumer 崩溃
   ↓
3. Consumer 重启
   ↓
4. 从上次提交的 Offset（100）继续消费
   ↓
5. 不会丢失消息，也不会重复消费
```

#### 项目中的实现

**go-queue/kq 库**：
- **自动恢复**：Consumer 重启后，自动从上次提交的 Offset 继续消费
- **Offset 存储**：Offset 存储在 Kafka 的 `__consumer_offsets` Topic 中
- **容错机制**：即使 Consumer 崩溃，已提交的 Offset 仍然保存

**代码示例**：
```go
// Consumer 重启后，kq 库会自动从上次 Offset 继续消费
consumer := kq.MustNewQueue(conf, handler)
consumer.Start()  // 自动从上次 Offset 继续
```

### 4. Offset 重置

**场景**：需要重新处理历史消息时，重置 Offset。

#### 重置方式

**方式 1：使用命令行工具**
```bash
# 重置 Consumer Group 的 Offset 到 earliest
kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group data-flow-default-group-1888 \
  --topic sol-trades \
  --reset-offsets \
  --to-earliest \
  --execute
```

**方式 2：修改配置**
```yaml
KqSol:
  Offset: first  # 从最早的消息开始消费
```

**使用场景**：
- **数据修复**：发现历史数据有问题，需要重新处理
- **新功能上线**：新功能需要处理历史数据
- **测试**：测试环境需要处理完整的数据集

### 5. Offset 和 Consumer Group 的关系

**场景**：不同的 Consumer Group 维护独立的 Offset。

#### 项目中的实际应用

**示例**：
```
Topic: sol-trades (3 个 Partition)

Consumer Group 1: data-flow-default-group-1888
  - Offset 0: 1000
  - Offset 1: 2000
  - Offset 2: 1500

Consumer Group 2: data-kline-group-api
  - Offset 0: 500   ← 独立维护自己的 Offset
  - Offset 1: 1000
  - Offset 2: 800
```

**项目中的使用**：

| 服务 | Consumer Group | Offset 用途 |
|------|---------------|------------|
| **Dataflow** | `data-flow-default-group-1888` | 记录 K 线生成的消费进度 |
| **Market** | `data-flow-default-group-1888` | 与 Dataflow 共享 Offset（负载均衡） |
| **Smart Money** | `data-kline-group-api` | 记录智能资金追踪的消费进度 |

**说明**：
- 同一个 Consumer Group 中的 Consumer 共享 Offset
- 不同的 Consumer Group 独立维护自己的 Offset
- 每个 Consumer Group 可以独立消费所有 Partition 的消息

### 6. Offset 和消息顺序

**场景**：确保消息按顺序处理。

#### 顺序保证

- **Partition 级别**：同一个 Partition 内的消息按 Offset 顺序处理
- **Consumer Group 级别**：同一个 Consumer Group 中的 Consumer 按 Offset 顺序消费

**项目中的实现**：
```go
func (t *TradeConsumer) Consume(ctx context.Context, key kafka.Message) error {
    // kafka-go 库保证同一个 Partition 的消息按 Offset 顺序到达
    // 处理消息
    processMessage(key)
    
    return nil  // 按顺序提交 Offset
}
```

**注意**：
- 如果消息处理失败，Offset 不会被提交
- 消息会被重试，但顺序仍然保证
- 如果使用并发处理（Processors > 1），顺序可能被打乱

---

## Offset 最佳实践

### 1. **选择合适的初始 Offset**

```yaml
# 生产环境：只处理新消息
Offset: last

# 开发/测试环境：需要处理历史数据
Offset: first
```

### 2. **监控 Consumer Lag**

```bash
# 定期检查 Consumer Group 的 Lag
kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group data-flow-default-group-1888 \
  --describe
```

**告警规则**：
- `LAG > 10000`：消费延迟严重，需要增加 Consumer 实例
- `LAG = 0`：消费正常

### 3. **处理消息失败时的 Offset 管理**

```go
func Consume(ctx context.Context, key kafka.Message) error {
    // 处理消息
    if err := processMessage(key); err != nil {
        // 返回错误，Offset 不会被提交
        // 消息会被重试
        return err
    }
    
    // 处理成功，Offset 会被提交
    return nil
}
```

### 4. **批量处理时的 Offset 提交**

```go
func Consume(ctx context.Context, key kafka.Message) error {
    // 添加到批量队列
    batch = append(batch, key)
    
    if len(batch) >= batchSize {
        // 批量处理
        if err := processBatch(batch); err != nil {
            // 批量处理失败，不提交 Offset
            return err
        }
        
        // 批量处理成功，提交 Offset
        return nil
    }
    
    return nil
}
```

### 5. **避免 Offset 提交失败**

- **网络问题**：确保 Consumer 与 Broker 的网络连接稳定
- **超时设置**：合理设置 `session.timeout.ms` 和 `heartbeat.interval.ms`
- **重试机制**：Offset 提交失败时，Consumer 会自动重试

---

## 相关文档

- [Consumer 消费者](./5.Consumer消费者.md)
- [Consumer Group 消费者组](./5.1.消费者组.md)
- [Partition 分区](./3.Partition分区.md)
- [Topic 主题](./2.Topic主题.md)
