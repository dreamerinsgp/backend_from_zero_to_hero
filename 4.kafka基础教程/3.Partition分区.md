# Partition（分区）

## Q1: 什么是Partition？

### 核心定义

**Partition（分区）** 是 Kafka Topic 的物理分割单元，每个 Partition 是一个有序的、不可变的消息序列。

### 关键特性

#### **1. 物理存储单元**
- Partition 是消息实际存储的地方
- 每个 Partition 在 Broker 上对应一个独立的目录
- 消息以追加写入（Append-Only）的方式存储

#### **2. 有序性保证**
- **Partition 内部有序**：同一 Partition 内的消息按照写入顺序存储
- **全局无序**：不同 Partition 之间的消息顺序不保证
- **Key 路由保证**：相同 Key 的消息总是路由到同一 Partition，保证该 Key 的消息有序

#### **3. 分区编号**
- Partition 从 0 开始编号（Partition 0, 1, 2, ...）
- 每个 Topic 可以有多个 Partition（如 `sol-trades` Topic 有 3 个 Partition）

---

### 存储结构示例

```
Broker 文件系统:
/var/kafka-logs/
  ├── sol-trades-0/              ← Partition 0 的目录
  │   ├── 00000000000000000000.log
  │   ├── 00000000000000000000.index
  │   └── 00000000000000000000.timeindex
  │
  ├── sol-trades-1/              ← Partition 1 的目录
  │   ├── 00000000000000000000.log
  │   ├── 00000000000000000000.index
  │   └── 00000000000000000000.timeindex
  │
  └── sol-trades-2/              ← Partition 2 的目录
      ├── 00000000000000000000.log
      ├── 00000000000000000000.index
      └── 00000000000000000000.timeindex
```

---

### Partition 与 Topic 的关系

```
Topic: sol-trades
  ├── Partition 0  (存储 slot-100, slot-103, slot-106, ...)
  ├── Partition 1  (存储 slot-123, slot-126, slot-129, ...)
  └── Partition 2  (存储 slot-101, slot-104, slot-107, ...)
```

**关系总结**：
- **1 个 Topic** = **多个 Partition**（实现并行处理）
- **1 个 Partition** = **1 个有序消息队列**
- **消息路由**：根据 Key 的 Hash 值选择 Partition

---

## Q2: 分区如何实现并行处理？

### 并行处理的原理

Partition 通过**水平分割**实现并行处理，多个 Partition 可以同时被不同的 Producer/Consumer 处理。

---

### 1. Producer 并行写入

#### **多个 Partition = 多个写入通道**

```
Producer 发送消息:
  Message 1 (Key: "slot-100") → Hash % 3 = 0 → Partition 0
  Message 2 (Key: "slot-123") → Hash % 3 = 1 → Partition 1  ← 并行写入
  Message 3 (Key: "slot-101") → Hash % 3 = 2 → Partition 2
```

**优势**：
- ✅ 3 个 Partition 可以**同时接收**3 条消息
- ✅ 写入吞吐量 = Partition 数量 × 单个 Partition 吞吐量
- ✅ 提高 Producer 的并发能力

---

### 2. Consumer 并行消费

#### **Consumer Group 分配 Partition**

```
Consumer Group: data-flow-group
  ├── Consumer 1 → 负责 Partition 0  ← 并行消费
  ├── Consumer 2 → 负责 Partition 1
  └── Consumer 3 → 负责 Partition 2
```

**工作原理**：
1. Consumer Group 中的每个 Consumer 负责**一个或多个 Partition**
2. 每个 Partition 只能被**同一个 Consumer Group 中的一个 Consumer** 消费
3. 多个 Consumer 可以**同时**从不同的 Partition 读取消息

---

### 3. 实际性能对比

#### **单 Partition vs 多 Partition**

| 场景 | Partition 数量 | 吞吐量 | 说明 |
|------|---------------|--------|------|
| **单 Partition** | 1 | 10,000 msg/s | 所有消息串行处理 |
| **3 个 Partition** | 3 | ~30,000 msg/s | 3 个 Partition 并行处理 |
| **10 个 Partition** | 10 | ~100,000 msg/s | 10 个 Partition 并行处理 |

**注意**：实际吞吐量受网络、磁盘 I/O、消息大小等因素影响。

---

### 4. 项目中的并行处理示例

#### **Producer 端（使用 HashPartitioner）**

```go
// apps/market/internal/mqs/producer/producer.go
config := sarama.NewConfig()
config.Producer.Partitioner = sarama.NewHashPartitioner  // ← 使用 Hash 分区器

// 发送消息时，根据 Key 自动路由到不同 Partition
_kfakaClient.Input() <- &sarama.ProducerMessage{
    Topic: "sol-trades",
    Key:   sarama.StringEncoder("slot-123"),  // ← Key 用于分区路由
    Value: sarama.ByteEncoder(tradeData),
}
```

**分区路由逻辑**：
```go
// Kafka 内部实现（简化版）
partition = hash(key) % partitionCount
// 例如: hash("slot-123") % 3 = 1 → Partition 1
```

---

#### **Consumer 端（并行消费）**

```go
// apps/market/internal/mqs/consumers/trade_consumer.go
reader := kafka.NewReader(kafka.ReaderConfig{
    Brokers:  []string{"localhost:9092"},
    Topic:    "sol-trades",
    GroupID:  "data-flow-group",  // ← Consumer Group
    MinBytes: 10e3,
    MaxBytes: 10e6,
})

// Consumer Group 自动分配 Partition
// 如果有 3 个 Consumer 实例，每个负责 1 个 Partition
message, _ := reader.ReadMessage(ctx)
// message.Partition = 1  ← 从 Partition 1 读取
```

**并行消费效果**：
- 3 个 Consumer 实例 → 3 个 Partition → **3 倍吞吐量**

---

### 5. 扩展性：增加 Partition 数量

#### **何时需要增加 Partition？**

- ✅ **吞吐量不足**：当前 Partition 数量无法满足消息处理需求
- ✅ **Consumer 数量增加**：需要更多 Consumer 并行处理
- ✅ **热点 Partition**：某个 Partition 负载过高

#### **如何增加 Partition？**

```bash
# 使用 kafka-topics.sh 增加 Partition 数量
kafka-topics.sh --alter \
  --topic sol-trades \
  --partitions 6 \
  --bootstrap-server localhost:9092
```

**注意**：
- ⚠️ Partition 数量**只能增加，不能减少**
- ⚠️ 增加 Partition 后，需要重新平衡 Consumer Group
- ⚠️ 新消息会路由到新的 Partition，但旧消息仍在原 Partition

---

### 并行处理总结

| 方面 | 单 Partition | 多 Partition |
|------|-------------|-------------|
| **写入速度** | 慢（串行） | 快（并行） |
| **消费速度** | 慢（单 Consumer） | 快（多 Consumer） |
| **扩展性** | 差 | 好（可增加 Partition） |
| **顺序保证** | 全局有序 | 仅 Partition 内有序 |
| **适用场景** | 低吞吐量 | 高吞吐量 |

---

## Q3: 如何追踪消息的分区信息？

### 追踪分区信息的方法

在 Kafka 中，每条消息都包含分区信息（Partition）和偏移量（Offset），可以通过多种方式追踪。

---

### 1. Producer 端：获取发送结果

#### **同步 Producer（返回 Partition 和 Offset）**

```go
// apps/consumer/internal/logic/mq/producer.go
message := &sarama.ProducerMessage{
    Topic: topic,
    Key:   &accessLogEntry{encoded: []byte(key)},
    Value: &accessLogEntry{encoded: data},
}

// SendMessage 返回 partition, offset, error
partition, offset, err := _kafkaClient.SendMessage(message)
if err != nil {
    logx.Errorf("[kafka] send event log to kafka failed: error:%v", err)
    return err
}

// 记录分区和偏移量信息
logx.Infof("[kafka] send event log to kafka success: %v:%v:%v, %v, len(data): %v",
    topic, partition, offset, key, len(data))
// 输出示例: sol-trades:1:12345, slot-123, len(data): 1024
```

**返回值说明**：
- `partition` (int32): 消息被发送到的 Partition 编号（0, 1, 2, ...）
- `offset` (int64): 消息在 Partition 中的偏移量（唯一标识）
- `err` (error): 发送错误（如果有）

---

#### **异步 Producer（通过回调获取）**

```go
// 配置异步 Producer 返回成功信息
config.Producer.Return.Successes = true

producer, _ := sarama.NewAsyncProducer(brokers, config)

// 发送消息
producer.Input() <- &sarama.ProducerMessage{
    Topic: "sol-trades",
    Key:   sarama.StringEncoder("slot-123"),
    Value: sarama.ByteEncoder(data),
}

// 通过 Successes channel 获取分区信息
go func() {
    for success := range producer.Successes() {
        partition := success.Partition
        offset := success.Offset
        logx.Infof("Message sent - Partition: %d, Offset: %d", partition, offset)
    }
}()
```

---

### 2. Consumer 端：读取消息元数据

#### **使用 kafka-go 库**

```go
// apps/market/internal/mqs/consumers/trade_consumer.go
reader := kafka.NewReader(kafka.ReaderConfig{
    Brokers:  []string{"localhost:9092"},
    Topic:    "sol-trades",
    GroupID:  "data-flow-group",
    MinBytes: 10e3,
    MaxBytes: 10e6,
})

message, err := reader.ReadMessage(ctx)
if err != nil {
    return err
}

// 获取分区和偏移量信息
partition := message.Partition  // int
offset := message.Offset        // int64
topic := message.Topic          // string

// 项目中实际使用
logx.Infof("kafka key offset: %d, partition: %d, time: %v", 
    offset, partition, msg.CreateTime.Format(time.DateTime))
// 输出示例: kafka key offset: 12345, partition: 1, time: 2024-01-15 10:30:00
```

---

#### **使用 sarama 库**

```go
// 使用 sarama Consumer
consumer, _ := sarama.NewConsumer(brokers, config)

partitionConsumer, _ := consumer.ConsumePartition("sol-trades", 1, sarama.OffsetNewest)

for {
    select {
    case message := <-partitionConsumer.Messages():
        partition := message.Partition  // int32
        offset := message.Offset        // int64
        topic := message.Topic          // string
        
        logx.Infof("Received message - Topic: %s, Partition: %d, Offset: %d",
            topic, partition, offset)
    }
}
```

---

### 3. 消息元数据结构

#### **完整的消息元数据**

```go
// kafka-go 的 Message 结构
type Message struct {
    Topic     string    // Topic 名称
    Partition int       // Partition 编号
    Offset    int64     // 偏移量
    Key       []byte    // 消息 Key
    Value     []byte    // 消息内容
    Headers   []Header  // 消息头（可选）
    Time      time.Time // 消息时间戳
}

// sarama 的 ConsumerMessage 结构
type ConsumerMessage struct {
    Topic     string    // Topic 名称
    Partition int32     // Partition 编号
    Offset    int64     // 偏移量
    Key       []byte    // 消息 Key
    Value     []byte    // 消息内容
    Headers   []*RecordHeader  // 消息头（可选）
    Timestamp time.Time // 消息时间戳
}
```

---

### 4. 项目中的实际应用

#### **日志记录分区信息**

```go
// apps/market/internal/mqs/consumers/trade_consumer.go
// 在处理消息时记录分区和偏移量
logx.Infof("kafka key offset: %d, partition: %d, time: %v", 
    key.Offset, key.Partition, msg.CreateTime.Format(time.DateTime))

// apps/dataflow/internal/mqs/consumers/trade_consumer.go
// 记录更详细的信息
logc.Infof(ctx, "tradeConsumer sendTime: %v, blockTime: %d, receiveTime: %v, key partition: %d, chain id: %s", 
    tradeMsg[0].CreateTime.Format(time.DateTime), 
    tradeMsg[0].BlockTime, 
    timeStr, 
    key.Partition,  // ← 分区信息
    tradeMsg[0].ChainId)
```

---

### 5. 使用命令行工具追踪

#### **查看 Consumer Group 的 Partition 分配**

```bash
# 查看 Consumer Group 中每个 Consumer 负责哪些 Partition
kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --group data-flow-group \
  --describe

# 输出示例:
# TOPIC           PARTITION  CURRENT-OFFSET  LAG  CONSUMER-ID
# sol-trades      0          10000          0     consumer-1
# sol-trades      1          15000          0     consumer-2
# sol-trades      2          12000          0     consumer-3
```

---

#### **查看特定 Partition 的消息**

```bash
# 从指定 Partition 读取消息（包含分区和偏移量信息）
kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic sol-trades \
  --partition 1 \
  --from-beginning \
  --property print.partition=true \
  --property print.offset=true

# 输出示例:
# Partition:1 Offset:0    {"trade": "data"}
# Partition:1 Offset:1    {"trade": "data"}
# Partition:1 Offset:2    {"trade": "data"}
```

---

### 6. 监控和调试技巧

#### **追踪消息流向**

```go
// 完整的消息追踪示例
func trackMessage(topic string, key string, data []byte) {
    // 1. Producer 发送
    partition, offset, err := producer.SendMessage(&sarama.ProducerMessage{
        Topic: topic,
        Key:   sarama.StringEncoder(key),
        Value: sarama.ByteEncoder(data),
    })
    
    if err != nil {
        logx.Errorf("Send failed: %v", err)
        return
    }
    
    // 2. 记录发送信息
    logx.Infof("Message sent - Topic: %s, Partition: %d, Offset: %d, Key: %s",
        topic, partition, offset, key)
    
    // 3. Consumer 接收时验证
    // （在实际 Consumer 代码中）
    // logx.Infof("Message received - Topic: %s, Partition: %d, Offset: %d, Key: %s",
    //     message.Topic, message.Partition, message.Offset, string(message.Key))
}
```

---

### 7. 常见使用场景

#### **场景 1：调试消息路由问题**

```go
// 检查消息是否路由到预期的 Partition
expectedPartition := hash(key) % partitionCount
actualPartition, offset, _ := producer.SendMessage(message)

if expectedPartition != actualPartition {
    logx.Warnf("Partition mismatch - Expected: %d, Actual: %d", 
        expectedPartition, actualPartition)
}
```

---

#### **场景 2：监控消费进度**

```go
// 记录每个 Partition 的消费进度
type PartitionProgress struct {
    Partition int32
    Offset    int64
    Lag       int64  // 消费延迟
}

func trackConsumerProgress(message *sarama.ConsumerMessage) {
    logx.Infof("Consumer progress - Partition: %d, Offset: %d",
        message.Partition, message.Offset)
}
```

---

#### **场景 3：实现消息重试（基于 Partition）**

```go
// 如果某个 Partition 的消息处理失败，可以记录 Partition 信息用于重试
func handleMessage(message *sarama.ConsumerMessage) error {
    err := processMessage(message.Value)
    if err != nil {
        // 记录失败消息的分区信息
        logx.Errorf("Failed to process - Partition: %d, Offset: %d, Error: %v",
            message.Partition, message.Offset, err)
        // 可以发送到重试 Topic，保留 Partition 信息
        return err
    }
    return nil
}
```

---

### 追踪分区信息总结

| 场景 | 方法 | 获取的信息 |
|------|------|-----------|
| **Producer 发送** | `SendMessage()` 返回值 | `partition`, `offset` |
| **Consumer 接收** | `Message.Partition`, `Message.Offset` | `partition`, `offset` |
| **异步 Producer** | `Successes` channel | `partition`, `offset` |
| **命令行工具** | `kafka-consumer-groups.sh` | Partition 分配、消费进度 |
| **日志记录** | 在代码中记录 | 用于调试和监控 |

---

### 最佳实践

1. ✅ **记录关键消息的分区信息**：便于调试和追踪
2. ✅ **监控 Partition 分配**：确保 Consumer Group 负载均衡
3. ✅ **使用 Offset 追踪消费进度**：及时发现消费延迟
4. ✅ **在日志中包含 Partition 信息**：快速定位问题消息
5. ✅ **避免硬编码 Partition 编号**：使用 Key 路由，让 Kafka 自动分配

---

**参考项目文件**：
- Producer: `apps/consumer/internal/logic/mq/producer.go`
- Consumer: `apps/market/internal/mqs/consumers/trade_consumer.go`
