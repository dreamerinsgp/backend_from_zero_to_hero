# Producer 批量发送

---

## Q1: 什么是批量发送？

**批量发送（Batching）**是指 Producer 将多条消息**累积在一起**，一次性发送到 Kafka Broker，而不是每条消息单独发送。

### 核心概念

- **消息累积**：Producer 在内存中累积多条消息
- **批量发送**：达到条件后，将累积的消息一次性发送
- **性能优化**：减少网络往返次数，提高吞吐量

### 批量发送的工作流程

```
1. Producer 收到消息 1
   ↓
2. 消息进入缓冲区（不立即发送）
   ↓
3. Producer 收到消息 2、3、4...
   ↓
4. 消息继续累积在缓冲区
   ↓
5. 达到批量发送条件（时间或大小）
   ↓
6. 一次性发送所有累积的消息
   ↓
7. Broker 接收批量消息并写入日志
```

### 批量发送 vs 单条发送

**单条发送**：
```
消息1 → 网络请求 → Broker
消息2 → 网络请求 → Broker
消息3 → 网络请求 → Broker
...
吞吐量：低（每次都需要网络往返）
```

**批量发送**：
```
消息1 ┐
消息2 ├→ 累积 → 批量发送 → Broker
消息3 ┘
...
吞吐量：高（多条消息共享一次网络请求）
```

---

## Q2: 什么情况下需要批量发送？

### ✅ **需要批量发送的场景**

#### **1. 高吞吐量场景**

```go
// 场景：每秒需要发送数千条消息
// 示例：市场数据流、日志收集
func streamMarketData(marketDataChan <-chan MarketData) {
    producer := initAsyncProducer()
    
    // 配置批量发送以提高吞吐量
    config.Producer.Flush.Messages = 100
    config.Producer.Flush.Frequency = 500 * time.Millisecond
    
    for data := range marketDataChan {
        producer.Input() <- &sarama.ProducerMessage{
            Topic: "market-data",
            Value: sarama.ByteEncoder(data.ToJSON()),
        }
    }
}
```

**适用场景**：
- 实时数据流（市场数据、日志流）
- 高并发场景
- 需要高吞吐量的业务

---

#### **2. 批量数据处理**

```go
// 场景：批量导入数据、ETL 任务
func batchImportData(items []DataItem) {
    producer := initAsyncProducer()
    
    // 配置批量发送
    config.Producer.Flush.Messages = 1000  // 达到 1000 条时批量发送
    config.Producer.Flush.Frequency = 1 * time.Second  // 或每 1 秒批量发送
    
    for _, item := range items {
        producer.Input() <- &sarama.ProducerMessage{
            Topic: "import-data",
            Value: sarama.ByteEncoder(item.ToJSON()),
        }
    }
    
    // 所有消息进入缓冲区，由 Producer 批量发送
}
```

**适用场景**：
- 数据导入
- ETL 任务
- 批量处理

---

#### **3. 可以容忍延迟的场景**

```go
// 场景：统计指标上报、监控数据
// 特点：可以容忍少量延迟，优先考虑吞吐量
func reportMetrics(metrics []Metrics) {
    producer := initAsyncProducer()
    
    // 配置批量发送，容忍一定延迟
    config.Producer.Flush.Messages = 100
    config.Producer.Flush.Frequency = 1 * time.Second  // 最多延迟 1 秒
    
    for _, metric := range metrics {
        producer.Input() <- &sarama.ProducerMessage{
            Topic: "metrics",
            Value: sarama.ByteEncoder(metric.ToJSON()),
        }
    }
}
```

**适用场景**：
- 统计指标上报
- 监控数据
- 非实时性要求高的场景

---

### ❌ **不需要批量发送的场景**

#### **1. 低延迟要求**

```go
// 场景：需要立即发送，不能等待批量
// 示例：关键业务事件、实时通知
func sendCriticalEvent(event CriticalEvent) error {
    // 使用同步发送，立即发送，不等待批量
    _, _, err := syncProducer.SendMessage(&sarama.ProducerMessage{
        Topic: "critical-events",
        Value: sarama.ByteEncoder(event.ToJSON()),
    })
    return err
}
```

**适用场景**：
- 关键业务事件
- 实时通知
- 低延迟要求

---

#### **2. 消息频率低**

```go
// 场景：消息发送频率很低（如每分钟几条）
// 批量发送意义不大，反而可能增加延迟
func sendLowFrequencyMessage(message Message) {
    // 直接发送，不需要批量
    syncProducer.SendMessage(...)
}
```

**适用场景**：
- 低频消息
- 事件驱动场景

---

## Q3: 如何批量发送?

### 方式 1：使用 Kafka Producer 内置批量机制（推荐）

Kafka Producer **默认启用批量发送**，通过配置参数控制批量行为。

#### **关键配置参数**

```go
config := sarama.NewConfig()

// 1. 批量大小（字节）
// 当累积的消息达到这个大小时，立即发送
config.Producer.Flush.Bytes = 16384  // 16KB（默认值）

// 2. 批量消息数量
// 当累积的消息数量达到这个值时，立即发送
config.Producer.Flush.Messages = 100  // 达到 100 条时发送

// 3. 批量发送频率（时间）
// 即使未达到大小或数量，也会定期发送
config.Producer.Flush.Frequency = 500 * time.Millisecond  // 每 500ms 发送一次

// 4. 等待时间（Linger）
// 发送前等待更多消息的时间
config.Producer.Flush.Messages = 0  // 禁用基于消息数的批量
config.Producer.Flush.Frequency = 0  // 禁用基于时间的批量
// 使用 linger.ms（在 sarama 中通过其他方式配置）
```

#### **批量发送的触发条件**

批量发送会在以下**任一条件**满足时触发：

1. **达到批量大小**：`Flush.Bytes`（如 16KB）
2. **达到消息数量**：`Flush.Messages`（如 100 条）
3. **达到时间间隔**：`Flush.Frequency`（如 500ms）

**示例**：

```go
config := sarama.NewConfig()

// 配置：达到 100 条消息 OR 达到 16KB OR 每 500ms
config.Producer.Flush.Messages = 100
config.Producer.Flush.Bytes = 16384
config.Producer.Flush.Frequency = 500 * time.Millisecond

// 批量发送会在以下情况触发：
// 1. 累积了 100 条消息 → 立即发送
// 2. 累积了 16KB 数据 → 立即发送
// 3. 距离上次发送已过 500ms → 立即发送（即使未达到大小或数量）
```

---

### 方式 2：手动实现批量发送

如果内置批量机制不满足需求，可以手动实现批量发送逻辑。

#### **示例：基于时间的批量发送**

```go
package main

import (
    "sync"
    "time"
    "github.com/IBM/sarama"
    "github.com/zeromicro/go-zero/core/logx"
)

type BatchProducer struct {
    producer    sarama.AsyncProducer
    batchSize   int
    flushPeriod time.Duration
    messages    []*sarama.ProducerMessage
    mu          sync.Mutex
    ticker      *time.Ticker
}

func NewBatchProducer(producer sarama.AsyncProducer, batchSize int, flushPeriod time.Duration) *BatchProducer {
    bp := &BatchProducer{
        producer:    producer,
        batchSize:   batchSize,
        flushPeriod: flushPeriod,
        messages:    make([]*sarama.ProducerMessage, 0, batchSize),
        ticker:      time.NewTicker(flushPeriod),
    }
    
    // 启动定时刷新
    go bp.autoFlush()
    
    return bp
}

func (bp *BatchProducer) Send(message *sarama.ProducerMessage) {
    bp.mu.Lock()
    defer bp.mu.Unlock()
    
    bp.messages = append(bp.messages, message)
    
    // 达到批量大小时立即发送
    if len(bp.messages) >= bp.batchSize {
        bp.flush()
    }
}

func (bp *BatchProducer) flush() {
    if len(bp.messages) == 0 {
        return
    }
    
    // 批量发送所有消息
    for _, msg := range bp.messages {
        bp.producer.Input() <- msg
    }
    
    logx.Infof("Flushed %d messages", len(bp.messages))
    bp.messages = bp.messages[:0]  // 清空
}

func (bp *BatchProducer) autoFlush() {
    for range bp.ticker.C {
        bp.mu.Lock()
        bp.flush()
        bp.mu.Unlock()
    }
}

func (bp *BatchProducer) Close() {
    bp.ticker.Stop()
    bp.mu.Lock()
    bp.flush()  // 关闭前刷新剩余消息
    bp.mu.Unlock()
    bp.producer.AsyncClose()
}
```

**使用示例**：

```go
producer := initAsyncProducer()
batchProducer := NewBatchProducer(producer, 100, 500*time.Millisecond)

// 发送消息（会自动批量）
for i := 0; i < 1000; i++ {
    batchProducer.Send(&sarama.ProducerMessage{
        Topic: "test",
        Value: sarama.ByteEncoder([]byte(fmt.Sprintf("message-%d", i))),
    })
}

// 关闭时会自动刷新剩余消息
defer batchProducer.Close()
```

---

### 方式 3：使用 Channel 缓冲实现批量发送

```go
package main

import (
    "sync"
    "time"
    "github.com/IBM/sarama"
)

type BufferedProducer struct {
    producer    sarama.AsyncProducer
    input       chan *sarama.ProducerMessage
    batchSize   int
    flushPeriod time.Duration
    wg          sync.WaitGroup
}

func NewBufferedProducer(producer sarama.AsyncProducer, batchSize int, flushPeriod time.Duration) *BufferedProducer {
    bp := &BufferedProducer{
        producer:    producer,
        input:       make(chan *sarama.ProducerMessage, batchSize*2),
        batchSize:   batchSize,
        flushPeriod: flushPeriod,
    }
    
    bp.wg.Add(1)
    go bp.batchLoop()
    
    return bp
}

func (bp *BufferedProducer) Send(message *sarama.ProducerMessage) {
    bp.input <- message
}

func (bp *BufferedProducer) batchLoop() {
    defer bp.wg.Done()
    
    batch := make([]*sarama.ProducerMessage, 0, bp.batchSize)
    ticker := time.NewTicker(bp.flushPeriod)
    defer ticker.Stop()
    
    flush := func() {
        if len(batch) > 0 {
            for _, msg := range batch {
                bp.producer.Input() <- msg
            }
            batch = batch[:0]
        }
    }
    
    for {
        select {
        case msg := <-bp.input:
            batch = append(batch, msg)
            if len(batch) >= bp.batchSize {
                flush()
            }
        case <-ticker.C:
            flush()
        }
    }
}

func (bp *BufferedProducer) Close() {
    close(bp.input)
    bp.wg.Wait()
    bp.producer.AsyncClose()
}
```

---

## Q4：项目中批量发送的场景？

根据项目代码分析，**项目中主要使用 Kafka Producer 的默认批量发送机制**，没有显式配置批量参数。

### 1. Market 服务 - 异步 Producer（默认批量发送）

**位置**：`apps/market/internal/mqs/producer/producer.go`

**当前配置**：

```go
func newAccessLogProducer(brokers []string, username, password string) (sarama.AsyncProducer, error) {
    config := sarama.NewConfig()
    
    // 注意：批量发送配置被注释掉了
    //config.Producer.Flush.Frequency = 500 * time.Millisecond // Flush batches every 500ms
    
    // 其他配置...
    config.Producer.RequiredAcks = sarama.WaitForLocal
    config.Producer.Partitioner = sarama.NewHashPartitioner
    
    producer, err := sarama.NewAsyncProducer(brokers, config)
    return producer, err
}
```

**实际行为**：
- ✅ **使用默认批量发送**：Kafka Producer 默认启用批量发送
- ✅ **默认批量大小**：通常为 16KB（`batch.size`）
- ✅ **默认等待时间**：通常为 5ms（`linger.ms`）
- ⚠️ **未显式配置**：`Flush.Frequency` 被注释掉，使用默认值

**发送场景**：

```go
// 实际代码：apps/market/internal/mqs/producer/sendkline.go
func SendKlinesToKafka(config config.Config, chainId int64, pairAddress string, klines *datakline.Klines) {
    // 1. Protobuf 序列化
    bytes, err := proto.Marshal(klines)
    
    // 2. 异步发送（会自动批量）
    err = SendMessage(topic, pairAddress, bytes)
    // 消息进入 Producer 缓冲区，由 Producer 自动批量发送
}
```

**为什么使用默认批量发送？**
- ✅ **异步 Producer 自动批量**：异步 Producer 默认会批量发送
- ✅ **高吞吐量需求**：K 线数据更新频繁，批量发送可以提高吞吐量
- ✅ **简单可靠**：使用默认配置，无需额外代码

---

### 2. Consumer 服务 - 同步 Producer（不批量发送）

**位置**：`apps/consumer/internal/logic/mq/producer.go`

**当前配置**：

```go
func newAccessLogProducer(...) (sarama.SyncProducer, error) {
    config := sarama.NewConfig()
    
    // 同步 Producer，没有配置批量发送参数
    // 同步发送通常不批量，每条消息立即发送
    
    producer, err := sarama.NewSyncProducer(brokers, config)
    return producer, err
}
```

**实际行为**：
- ✅ **同步发送**：每条消息立即发送，不等待批量
- ✅ **可靠性优先**：需要立即知道发送结果
- ❌ **不批量发送**：同步 Producer 通常不批量

**发送场景**：

```go
// 实际代码：apps/consumer/internal/logic/sol/block/send.go
func (s *BlockService) SendTx(_ context.Context, slot int64, trades []*types.TradeWithPair) {
    // 1. 序列化交易数据（已经是批量数据）
    tradeListJsons, err := json.Marshal(trades)  // 多条交易打包成一条消息
    
    // 2. 同步发送（不批量，立即发送）
    err = mq.SendEventLogKafkaInfoMessage(SolTradeTopic, fmt.Sprintf("%v", slot), tradeListJsons)
    // 虽然 trades 是数组，但作为一条消息发送
}
```

**特点**：
- ✅ **消息级别批量**：虽然不批量发送多条消息，但将多条交易数据打包成一条消息
- ✅ **可靠性优先**：同步发送确保消息立即到达

---

### 3. Dataflow 服务 - 批量保存到数据库（非 Kafka 批量发送）

**位置**：`apps/dataflow/internal/mqs/consumers/trade_consumer.go`

**场景**：虽然这不是 Producer 的批量发送，但展示了批量处理的思想。

```go
// ticker processes klines in batches or when the ticker fires
func (t *TradeConsumer) ticker() {
    const (
        batchSize  = 10000  // 批量大小：10000 条
        tickPeriod = time.Millisecond * 500  // 刷新周期：500ms
    )

    ticker := time.NewTicker(tickPeriod)
    defer ticker.Stop()

    batch := make([]*datakline.Kline, 0, batchSize)

    flush := func() {
        if len(batch) > 0 {
            t.saveKlineToDB(batch)  // 批量保存到数据库
            batch = make([]*datakline.Kline, 0, batchSize)
        }
    }

    for {
        select {
        case <-t.ctx.Done():
            flush()
            return
        case msg := <-config.KlineProcessedCh:
            batch = append(batch, msg)
            if len(batch) >= batchSize {
                flush()  // 达到批量大小时立即保存
            }
        case <-ticker.C:
            flush()  // 定时保存（即使未达到批量大小）
        }
    }
}
```

**特点**：
- ✅ **批量保存**：将 K 线数据批量保存到数据库（不是 Kafka 批量发送）
- ✅ **双重触发**：达到批量大小或时间间隔时触发
- ✅ **性能优化**：减少数据库写入次数

---

## Kafka Producer 批量发送的配置详解

### 1. **批量大小（Batch Size）**

```go
// sarama 中的配置（通过 Flush.Bytes）
config.Producer.Flush.Bytes = 16384  // 16KB

// 说明：
// - 当累积的消息达到这个大小时，立即发送
// - 默认值：16KB
// - 建议值：16KB - 1MB（取决于消息大小）
```

**影响**：
- **太小**：批量效果不明显，吞吐量低
- **太大**：内存占用高，延迟增加

---

### 2. **批量消息数量（Flush Messages）**

```go
// sarama 中的配置
config.Producer.Flush.Messages = 100

// 说明：
// - 当累积的消息数量达到这个值时，立即发送
// - 默认值：0（禁用，只基于大小和时间）
// - 建议值：100-1000（取决于消息大小）
```

**影响**：
- **太小**：批量效果不明显
- **太大**：延迟增加

---

### 3. **批量发送频率（Flush Frequency）**

```go
// sarama 中的配置
config.Producer.Flush.Frequency = 500 * time.Millisecond

// 说明：
// - 即使未达到大小或数量，也会定期发送
// - 默认值：0（禁用，只基于大小和数量）
// - 建议值：100ms - 1s（取决于延迟要求）
```

**影响**：
- **太小**：批量效果不明显
- **太大**：延迟增加

---

### 4. **等待时间（Linger）**

```go
// Kafka 配置（在 sarama 中通过其他方式实现）
linger.ms = 5  // 等待 5ms 以累积更多消息

// 说明：
// - 发送前等待更多消息的时间
// - 默认值：5ms
// - 建议值：0-100ms（0 表示不等待）
```

**影响**：
- **0**：不等待，立即发送（低延迟，低吞吐量）
- **5-100ms**：平衡延迟和吞吐量
- **> 100ms**：高吞吐量，但延迟较高

---

## 批量发送的最佳实践

### 1. **根据场景选择配置**

```go
// 场景 1：高吞吐量，可容忍延迟
config.Producer.Flush.Bytes = 65536  // 64KB
config.Producer.Flush.Messages = 1000
config.Producer.Flush.Frequency = 1 * time.Second

// 场景 2：平衡吞吐量和延迟
config.Producer.Flush.Bytes = 16384  // 16KB
config.Producer.Flush.Messages = 100
config.Producer.Flush.Frequency = 500 * time.Millisecond

// 场景 3：低延迟优先
config.Producer.Flush.Bytes = 0  // 禁用基于大小的批量
config.Producer.Flush.Messages = 0  // 禁用基于数量的批量
config.Producer.Flush.Frequency = 100 * time.Millisecond  // 只基于时间
```

---

### 2. **监控批量效果**

```go
// 监控批量大小和频率
var (
    batchSizeHistogram = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "kafka_producer_batch_size_bytes",
            Help: "Batch size in bytes",
        },
        []string{"topic"},
    )
    
    batchCountHistogram = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "kafka_producer_batch_count",
            Help: "Number of messages per batch",
        },
        []string{"topic"},
    )
)

// 在发送成功后记录
go func() {
    for success := range producer.Successes() {
        batchSizeHistogram.WithLabelValues(success.Topic).Observe(float64(success.Size))
        batchCountHistogram.WithLabelValues(success.Topic).Observe(float64(success.Count))
    }
}()
```

---

### 3. **性能调优建议**

#### **提高吞吐量**：

```go
// 1. 增加批量大小
config.Producer.Flush.Bytes = 65536  // 64KB

// 2. 增加批量消息数量
config.Producer.Flush.Messages = 1000

// 3. 增加等待时间
config.Producer.Flush.Frequency = 1 * time.Second

// 4. 启用压缩
config.Producer.Compression = sarama.CompressionSnappy
```

#### **降低延迟**：

```go
// 1. 减小批量大小
config.Producer.Flush.Bytes = 4096  // 4KB

// 2. 减小批量消息数量
config.Producer.Flush.Messages = 10

// 3. 减小等待时间
config.Producer.Flush.Frequency = 100 * time.Millisecond

// 4. 使用同步发送（不批量）
syncProducer.SendMessage(...)
```

---

## 项目中的批量发送总结

### 当前状态

| 服务 | Producer 类型 | 批量发送配置 | 实际行为 |
|------|--------------|------------|---------|
| **Consumer** | 同步 | 未配置 | 不批量发送，每条消息立即发送 |
| **Market** | 异步 | 未显式配置 | 使用默认批量发送（16KB 或 5ms） |

### 建议优化

#### **Market 服务**（如果需要优化）：

```go
func newAccessLogProducer(...) (sarama.AsyncProducer, error) {
    config := sarama.NewConfig()
    
    // 启用批量发送配置
    config.Producer.Flush.Messages = 100  // 达到 100 条时批量发送
    config.Producer.Flush.Frequency = 500 * time.Millisecond  // 每 500ms 批量发送
    config.Producer.Flush.Bytes = 16384  // 达到 16KB 时批量发送
    
    // 其他配置...
    
    producer, err := sarama.NewAsyncProducer(brokers, config)
    return producer, err
}
```

**优化效果**：
- ✅ 提高吞吐量（减少网络请求次数）
- ✅ 减少 Broker 负载
- ⚠️ 可能增加延迟（最多 500ms）

---

## 批量发送的注意事项

### 1. **内存占用**

```go
// 批量发送会增加内存占用
// 需要确保有足够的内存缓冲
config.Producer.Flush.Bytes = 65536  // 64KB 批量大小
// 如果有 100 个分区，可能需要 64KB * 100 = 6.4MB 内存
```

### 2. **延迟权衡**

```go
// 批量发送会增加延迟
// 需要根据业务需求平衡吞吐量和延迟
config.Producer.Flush.Frequency = 500 * time.Millisecond
// 消息最多延迟 500ms 才发送
```

### 3. **消息顺序**

```go
// 批量发送不会影响消息顺序
// 同一分区的消息仍然保持顺序
// 但不同分区的消息可能乱序
```

---

## 总结

### 项目中的批量发送策略

1. **Consumer 服务**：使用同步发送，不批量，可靠性优先
2. **Market 服务**：使用异步发送，默认批量，吞吐量优先

### 最佳实践建议

1. ✅ **高吞吐量场景**：启用批量发送，配置合适的批量大小和频率
2. ✅ **低延迟场景**：禁用批量发送或使用同步发送
3. ✅ **监控和调优**：监控批量效果，根据实际情况调整配置
4. ✅ **内存管理**：确保有足够的内存缓冲批量消息

---

## 相关文档

- [Producer 生产者](./4.Producer生产者.md)
- [两种发送方式](./4.1.两种发送方式.md)
- [消息重试和错误处理](./4.2.消息重试和错误处理.md)
