目标：
1. 理解clustered  Indexes 

视频：

录制：mysql基础7_索引优化策略_聚集索引和非聚集索引.mp4
日期：2026-01-26 19:25:13
录制文件：https://meeting.tencent.com/crm/2YDkwmaecc

录制：mysql基础8_聚集索引为什么要求顺序主键.mp4
日期：2026-01-26 19:20:29
录制文件：https://meeting.tencent.com/crm/23wz6ZDOcc


内容：
1. 定义
聚集索引它不是一个索引类型， 相反，它是一个数据存储方法。

2. 存储什么？
 InnoDB’s clustered indexes actually store a B-tree index and the rows together in the same structure.
1） 当一张表有聚集索引时，行数据会存储在索引的叶子节点,指向行信息的实际物理存储位置。 

2) 聚集的含义？
The term clustered refers to the fact that rows with adjacent key values are
stored close to one another

3. InnoDB存储引擎是如何聚集数据？ 
InnoDB clusters the data by the primary key. 
1）非叶子节点存储什么？
仅仅存储被索引的字段值（primary key 值）

2）叶子节点？
存储主键key的，事务ID和回滚指针，和主键对应的行记录信息

3）如果用户在创建表的时候，没有创建主键，那么还会有聚集索引吗？
会。 
方案1：InnoDB会尝试用表中定义的其它unique且非空的字段（索引） 来作为主键，实现聚集索引；
方案2：InnonDB会顶一个隐藏的主键，然后实现聚集索引。

4）使用方案2的缺点
假设有多张表都使用了隐藏的主键，那么这个主键会变成一个共享资源，会导致共享资源的锁竞争。 

4. 聚集数据的优点？
1）相关的数据存储在一起
2）数据获取会很快
3）...


5. 聚集数据的局限性？

1）如果数据查询并不需要太多次IO,所有数据完全可以加载到内存中，那么可以直接在内存中进行数据排序，这时候聚集索引带来的排序效果，直接收益就不大了。 

2）更新聚集索引字段很昂贵，因为它会强制要求InnoDB将每个被更新的row移动到新的位置。

3）当将数据移动到一个已经满了的page时，这个page会被拆分成两个page，这时候，这张表就会占用更大的磁盘空间。 

6. 非聚集索引
它的叶子节点包含了一个主键字段，指向了行数据信息。
1）非聚集索引如何查询行数据信息？
需要两次索引查询，第一次查找非聚集索引的叶子节点，拿到对于的primarky key值。然后基于priamarykey值，到primary key Index（聚集索引）中找到对于的行数据 信息。 



7. 实践部分

1）为什么乱序聚集索引比如UUID为主键，会存在如下情况？ 
The destination page might have been flushed to disk and removed from the
caches or might not have ever been placed into the caches, in which case InnoDB
will have to find it and read it from the disk before it can insert the new row. This
causes a lot of random I/O

详细解释：

问题场景：使用 UUID 作为主键（乱序插入）

示例对比：

情况1：自增 ID（顺序插入）
- 插入 ID=1, 2, 3, 4, 5...
- 数据按顺序存储在同一页（page）或相邻页
- 插入新行时，目标页很可能还在内存缓存中
- 只需要顺序 I/O，性能好

情况2：UUID 主键（乱序插入）
- 插入 UUID: 'a1b2c3...', 'f9e8d7...', '3x4y5z...'（完全随机）
- 数据随机分布在不同页
- 插入新行时，目标页可能：
  1. 不在缓存中（从未加载到内存）
  2. 曾经在缓存中，但已被刷到磁盘并移除（LRU 淘汰）
- 需要从磁盘随机读取目标页 = 随机 I/O

为什么会导致随机 I/O？

1. 缓存失效（Cache Miss）
   - 内存缓存有限（如 InnoDB buffer pool）
   - 使用 LRU（最近最少使用）算法管理缓存
   - 乱序插入导致：
     * 插入 UUID-A → 加载页1到内存
     * 插入 UUID-B → 加载页50到内存（页1可能被淘汰）
     * 插入 UUID-C → 加载页200到内存（页50可能被淘汰）
     * 再次插入 UUID-A 相关的数据 → 页1已不在缓存，需要从磁盘读取

2. 页面分散（Page Fragmentation）
   - 顺序插入：数据集中在少数页
     * 页1: [1, 2, 3, 4, 5]
     * 页2: [6, 7, 8, 9, 10]
   - 乱序插入：数据分散在多个页
     * 页1: [UUID-A, UUID-X]
     * 页50: [UUID-B]
     * 页200: [UUID-C, UUID-Y]
     * 页1000: [UUID-D]
   - 插入时需要访问不同的页，无法利用局部性原理

3. 随机 I/O vs 顺序 I/O
   - 顺序 I/O：连续读取磁盘，速度快（如 100MB/s）
   - 随机 I/O：跳转读取磁盘，速度慢（如 100-200 IOPS，每次几KB）
   - 随机 I/O 比顺序 I/O 慢 100-1000 倍！

实际影响：

插入操作流程（UUID 主键）：
1. 计算新 UUID 的哈希值，确定应该插入到哪个页
2. 检查该页是否在缓存中
3. 如果不在缓存：
   - 从磁盘读取该页（随机 I/O，慢！）
   - 加载到内存缓存
4. 在内存中插入新行
5. 如果页满了，需要页分裂（page split）
   - 创建新页
   - 移动部分数据到新页
   - 更新索引结构
   - 更多随机 I/O！

对比：自增 ID 插入
1. 新行总是插入到最后一页（或新页）
2. 该页很可能还在缓存中（最近使用过）
3. 直接插入，无需磁盘读取
4. 顺序 I/O，性能好

总结：
- 乱序主键 → 数据分散 → 缓存命中率低 → 频繁磁盘读取 → 随机 I/O → 性能差
- 顺序主键 → 数据集中 → 缓存命中率高 → 少磁盘读取 → 顺序 I/O → 性能好




结论
1. 必须选择单调递增的column作为我们的主键。不能选择随机的column来作为主键。 

2.随机主键的问题？ 
1）结果：导致更大的查询实践和更大的索引size 
原因：因为乱序的primary key会导致大量的分页操作，同时导致数据稀疏分布。 大量的新页就产生了更多的磁盘空间占用； 移动主键的同时，产生新页本省也会导致更多的时间消耗。 

